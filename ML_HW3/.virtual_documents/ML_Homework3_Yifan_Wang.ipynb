


import numpy as np
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import pandas as pd


# You should replace the data with the ones provided in the homework specification
X_train = pd.read_csv('X_train.csv').values.flatten()
y_train = pd.read_csv('y_train.csv').values.flatten()

X_val = pd.read_csv('X_val.csv').values.flatten().reshape(-1,1)
y_val = pd.read_csv('y_val.csv').values.flatten()

X_test = pd.read_csv('X_test.csv').values.flatten().reshape(-1,1)
y_test = pd.read_csv('y_test.csv').values.flatten()

print(X_train)

# sort the test data for plotting
test_data = sorted([(X_test[i], y_test[i]) for i in range(y_test.shape[0])], key=lambda x:x[0])
X_test = [d[0] for d in test_data]
y_test = [d[1] for d in test_data]
X_test = np.array(X_test).reshape(-1, 1)
y_test = np.array(y_test)
print(X_test.shape)
print(y_test.shape)


input_layer = layers.Input(shape=(1,)) 
hidden_layer = layers.Dense(800, activation='sigmoid')(input_layer) 
output_layer = layers.Dense(1, activation='linear')(hidden_layer) 

# Create the neural network model
model = keras.Model(inputs=input_layer, outputs=output_layer)

# Check model structure
model.summary()
model.layers

# Compile model
model.compile(loss='mean_squared_error', optimizer='adam')

# Fit model to training data with validation
history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, verbose=1)

# Evaluate model on test data
loss = model.evaluate(X_test, y_test)


# Plot the development of the loss function during training
plt.figure()
plt.plot(history.history['loss'], label='training loss')
plt.plot(history.history['val_loss'], label='validation loss')
plt.legend()
plt.show()

y_pred = model.predict(X_test)

# Plot predicted values and test data
plt.plot(X_test, y_pred, label='Approximation')
plt.plot(X_test, y_test, label='Actual')
plt.legend()
plt.show()

#provide test error
print(f'Test error: {loss}')





input_layer = layers.Input(shape=(1,)) 
hidden_layer1 = layers.Dense(1000, activation='relu')(input_layer) 
hidden_layer2 = layers.Dense(600, activation='swish')(hidden_layer1)
hidden_layer3 = layers.Dense(400, activation='relu')(hidden_layer2)
output_layer = layers.Dense(1, activation='linear')(hidden_layer3) 

# Create the neural network model
model = keras.Model(inputs=input_layer, outputs=output_layer)

# Check model structure
model.summary()
model.layers

# Compile model
model.compile(loss='mean_squared_error', optimizer='adam')

# Fit model to training data with validation
history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, verbose=1)

# Evaluate model on test data
loss = model.evaluate(X_test, y_test)
print(f'Test error: {loss}')


# Plot the development of the loss function during training
plt.figure()
plt.plot(history.history['loss'], label='training loss')
plt.plot(history.history['val_loss'], label='validation loss')
plt.legend()
plt.show()

y_pred = model.predict(X_test)

# Plot predicted values and test data
plt.plot(X_test, y_pred, label='Approximation')
plt.plot(X_test, y_test, label='Actual')
plt.legend()
plt.show()

#provide test error
print(f'Test error: {loss}')






